#!/usr/bin/env python

import argparse
from urllib.parse import urlparse, parse_qs
import json
import os
import logging
import re

import requests
import bs4

parser = argparse.ArgumentParser()
parser.add_argument('race', help='Race url fragment.')

args = parser.parse_args()
logging.basicConfig(level=logging.INFO)


logging.info('Getting Riders')

session = requests.Session()
session.headers['User-Agent'] = 'Mozilla/5.0 (X11; Linux x86_64; rv:39.0) Gecko/20100101 Firefox/39.0'

race_page_response = session.get('http://trackleaders.com/{}f.php'.format(args.race))
race_page_response.raise_for_status()
race_page = bs4.BeautifulSoup(race_page_response.text, "html.parser")
rider_links = (
    race_page
    .find(string=re.compile('All Riders.*'))
    .find_parent('h3')
    .next_sibling
    .find_all('a', title="Click for individual history")
)

riders = [
    {
        'url_fragment': parse_qs(urlparse(rider_link['href']).query)['name'][0],
        'name': rider_link.string,
    }
    for rider_link in rider_links
]


race_path = os.path.join('races', args.race)
if not os.path.exists(race_path):
    os.mkdir(race_path)

with open(os.path.join(race_path, 'riders.json'), 'w') as f:
    json.dump(riders, f, indent=2, sort_keys=True)
